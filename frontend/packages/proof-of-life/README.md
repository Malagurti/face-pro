# @face-pro/proof-of-life ‚Äì SDK Web (React)

SDK em React para prova de vida via WebSocket com o backend Face Pro. A UI mostra apenas a imagem da c√¢mera e a instru√ß√£o do desafio. Status/diagn√≥stico s√≥ aparecem quando `debug` estiver ativado.

## Instala√ß√£o

```bash
pnpm add @face-pro/proof-of-life
# ou
npm i @face-pro/proof-of-life
# ou
yarn add @face-pro/proof-of-life
```

## Pr√©‚Äërequisitos do backend

1) Criar sess√£o
```bash
curl -s -X POST http://localhost:8080/session | jq
# => { "session_id":"...", "token":"...", "challenges":[...] }
```
2) Use `session_id` e `token` ao iniciar o SDK.

## Uso b√°sico (Componente)

```tsx
import { ProofOfLife } from "@face-pro/proof-of-life";

export function Example() {
  const backendUrl = "http://localhost:8080";
  const sessionId = "..."; // do POST /session
  const token = "...";     // do POST /session

  return (
    <div>
      <h1>Prova de Vida</h1>
      <ProofOfLife
        backendUrl={backendUrl}
        sessionId={sessionId}
        token={token}
        debug={false}
        maxFps={15}
        videoConstraints={{
          width: { ideal: 320 },
          height: { ideal: 240 },
          frameRate: { ideal: 15 },
          facingMode: "user",
        }}
        enableClientHeuristics
        useFaceDetector
        minMotionScore={0.02}
        phashIntervalFrames={5}
        onResult={(passed) => console.log("result:", passed)}
        onError={(err) => console.error(err)}
      />
    </div>
  );
}
```

- O componente renderiza internamente um `<video data-proof-of-life>` e inicia/paralisa o fluxo automaticamente.
- A instru√ß√£o exibida reflete o `prompt` do backend (blink, open-mouth, turn-left/right, head-up/down).

## Uso com Hook (UI pr√≥pria)

```tsx
import { useEffect, useRef } from "react";
import { useProofOfLife } from "@face-pro/proof-of-life";

export function CustomUi() {
  const ref = useRef<HTMLVideoElement>(null);
  const { status, start, stop, lastPrompt, error } = useProofOfLife({
    backendUrl: "http://localhost:8080",
    sessionId: "...",
    token: "...",
  });

  useEffect(() => {
    start();
    return () => { stop(); };
  }, [start, stop]);

  return (
    <div>
      <video ref={ref} data-proof-of-life autoPlay playsInline muted width={240} height={320} />
      <div>{lastPrompt ? `Guia: ${lastPrompt.kind}` : null}</div>
      {error && <div>{error}</div>}
    </div>
  );
}
```

Observa√ß√£o: o hook busca um elemento `video[data-proof-of-life]` no DOM para capturar frames.

## Op√ß√µes (UseProofOfLifeOptions)

- backendUrl: string (ex.: `http://localhost:8080`)
- sessionId: string
- token: string
- videoConstraints?: MediaTrackConstraints
- maxFps?: number (default 15)
- enableClientHeuristics?: boolean (default true)
- useFaceDetector?: boolean (default true quando suportado)
- minMotionScore?: number (default 0.02)
- phashIntervalFrames?: number (default 5)
- **bypassValidation?: boolean (default false)** ‚Äì **NOVO**: modo bypass para hackathon

Props adicionais do componente:
- debug?: boolean (default false) ‚Äì exibe status/RTT/erros para diagn√≥stico
- onResult?: (passed: boolean) => void
- onError?: (err: string) => void

## Estados e eventos

- status: "idle" | "connecting" | "prompt" | "streaming" | "passed" | "failed"
- lastPrompt: `{ id: string; kind: string; timeoutMs: number }`
- onResult(passed): chamado ao final do fluxo

## Telemetria enviada (opcional)

- motionScore: n√∫mero (0‚Äì1) ‚Äì diferen√ßa m√©dia quadro‚Äëa‚Äëquadro (downscale 32√ó32)
- ahash: string (hex) ‚Äì hash perceptual simples peri√≥dico
- facePresent: boolean ‚Äì quando FaceDetector API dispon√≠vel
- faceBox: `{ x, y, width, height }` ‚Äì quando FaceDetector API dispon√≠vel

Esses dados ajudam o backend a validar (MVP) enquanto a valida√ß√£o "forte" por landmarks/pose √© integrada.

## üöÄ Modo Bypass para Hackathon

Para hackathons e testes de diferentes metodologias de valida√ß√£o no backend, o SDK agora oferece o modo `bypassValidation`. Quando ativado:

### Como usar

```tsx
<ProofOfLife
  backendUrl="http://localhost:8080"
  sessionId="..."
  token="..."
  bypassValidation={true}  // ‚ú® Modo bypass ativado
  enableClientHeuristics={false}  // Desabilitar processamento local
  enablePositionGuide={false}     // Desabilitar guias de posi√ß√£o
/>
```

### O que acontece no modo bypass

1. **MediaPipe √© desabilitado** - N√£o h√° processamento de detec√ß√£o facial local
2. **Captura completa de dados** - Todos os dados necess√°rios s√£o extra√≠dos dos frames
3. **Envio via WebSocket** - Dados brutos s√£o enviados para o backend processar

### Dados enviados no modo bypass

O SDK envia mensagens do tipo `bypassFrame` com os seguintes dados:

```json
{
  "type": "bypassFrame",
  "timestamp": 1234567890.123,
  "frameId": 1234567890123,
  "videoInfo": {
    "width": 320,
    "height": 240,
    "videoWidth": 320,
    "videoHeight": 240
  },
  "rawImageData": {
    "width": 320,
    "height": 240,
    "data": [255, 128, 64, 255, ...] // Array completo de pixels RGBA
  },
  "motionScore": 0.05,
  "ahash": "a1b2c3d4e5f6...",
  "features": {
    "brightness": 128.5,
    "contrast": 0,
    "sharpness": 0,
    "histogram": [0, 1, 2, 3, ...]  // Histograma de 256 posi√ß√µes
  }
}
```

### Dados para implementa√ß√£o de liveness

Os dados enviados cont√™m tudo necess√°rio para validar:

- **Piscar os olhos**: an√°lise de mudan√ßas na regi√£o dos olhos via `rawImageData`
- **Virar cabe√ßa (esquerda/direita)**: detec√ß√£o de movimento lateral via `motionScore` e an√°lise facial
- **Movimento de cabe√ßa (cima/baixo)**: detec√ß√£o de movimento vertical
- **Abrir boca**: an√°lise da regi√£o da boca
- **Express√µes faciais**: dados completos dos pixels para qualquer an√°lise

### Para o time de backend

1. **Conex√£o WebSocket**: Cliente envia `{ type: "hello", client: { bypassValidation: true } }`
2. **Recebimento de frames**: Escutar mensagens `bypassFrame` com dados completos
3. **Processamento**: Implementar algoritmos de detec√ß√£o usando os dados recebidos
4. **Resposta**: Continuar enviando `prompt` e `result` normalmente

### Benef√≠cios para hackathon

- ‚úÖ **Flexibilidade total**: Teste qualquer biblioteca/algoritmo no backend
- ‚úÖ **Dados completos**: Acesso a pixels brutos e features calculadas
- ‚úÖ **Performance**: Sem processamento pesado no frontend
- ‚úÖ **Compatibilidade**: Mant√©m protocolo WebSocket existente

## Boas pr√°ticas

- Use resolu√ß√£o baixa (ex.: 320√ó240) e 10‚Äì15 FPS para lat√™ncia/uso de rede ideais.
- Execute sob HTTPS/WSS em produ√ß√£o; pe√ßa permiss√£o de c√¢mera de forma clara.
- Em mobile, preserve a orienta√ß√£o ‚Äúportrait‚Äù para melhor enquadramento.

## Troubleshooting

- V√≠deo n√£o abre: verifique permiss√µes do navegador (camera/mic) e `facingMode: "user"`.
- Conex√£o WS cai: confirme `backendUrl`, CORS e limites de tamanho no backend.
- Performance: reduza `frameRate`/resolu√ß√£o ou desabilite FaceDetector (`useFaceDetector: false`).
- **Erro MediaPipe 404**: O SDK agora usa m√∫ltiplos fallbacks para os modelos de detec√ß√£o facial. Se todos falharem, a detec√ß√£o facial ser√° desabilitada mas o SDK continuar√° funcionando para captura de frames.

## Licen√ßa

MIT
